<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.189">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Kaylynn Xia">
<meta name="dcterms.date" content="2023-04-18">
<meta name="description" content="Limits of the Quantitative Approach Essay">

<title>My Awesome CSCI 0451 Blog - Hello Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<style>
    .quarto-title-block .quarto-title-banner {
      color: white;
background-image: url(../../img/landscape.png);
background-size: cover;
    }
    </style>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">My Awesome CSCI 0451 Blog</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">About</a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"><i class="bi bi-github" role="img">
</i> 
 </a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"><i class="bi bi-twitter" role="img">
</i> 
 </a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Hello Blog</h1>
                  <div>
        <div class="description">
          Limits of the Quantitative Approach Essay
        </div>
      </div>
                </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Kaylynn Xia </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">April 18, 2023</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>Part 1:</p>
<p>On April 24th, Timnit Gebru will be visiting Middlebury College to give a presentation on bias and social impacts of AI. Born and raised in Ethiopia, Timnit is an American computer scientist who works on algorithmic biases and data mining. She has been a vocal advocate for diversity in technology, she is the co-founder of Black in AI, a community of Black researchers working in AI, and she is the founder of the Distributed Artificial Intelligence Research Institute (DAIR). Timnit had a rough childhood ranging from her father’s death, feeling the Eritrean-Ethiopian war, being denied entry to the United States, and facing systematic racism in her early years of living in the United States. Her experiences led her to ethics in technology. In 2001, Timnit was accepted at Stanford University where she earned her Bachelor of Science and Master of Science degrees in electrical engineering and her PhD in computer vision. Shortly after her completing of her PhD, she joined Google where she co-led a team on the ethics of artificial intelligence. She studied the implications of artificial intelligence, looking to improve the ability of technology to do social good. However, just two years into her role, in December 2020, Gebru controversially departed from Google. Timnit had published a paper called “On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?” that covered the risks of large language models. In December 2020, Gebru’s employment ended after high Google managers asked her to either withdraw the paper or remove the names of all the Google employees from the paper. Gebru requested insight into their decision and warned that non-compliance would result in her departure. Google terminated her employment immediately, stating they were accepting her resignation. Aside from this controversy, Timnit has been widely recognized. She was named one of the World’s 50 Greatest Leaders by Fortune, won the 2019 AI Innovations Award in the category AI for Good for highlighting the significant problem of algorithmic bias in facial recognition, one of Nature’s ten people who shaped science in 2021, and one of Time’s most influential people in 2022.</p>
<p>Timnit Gebru discussed “faception” in the 2020 Fairness Accountability Transparency and Ethics in Computer Vision lecture. What is faception? She explains that it is the “first to-technology and first-to-market with proprietary computer vision and machine learning technology for profiling people and revealing their personality based only on their facial image”. It other words, it is an algorithm that can determine your IQ or see whether or not you are a terrorist based on one facial image. This type of technology is incredibly harmful because it incorrectly categorizes people, often in a negative way, and it negatively targets minorities and those in underrepresented groups. It’s technology like this that Gebru warns us about. It’s not just faception now. For example, the Hire Vue video intelligence that detects your verbal and non-verbal cues to determine whether you are qualified for a job. It determines whether you are ‘happy’ or ‘smart’, which are all very subjective descriptions. The Baltimore police also uses extensive facial recognition in an unconstitutional way. They used facial recognition to surveil people at protests and rallies – activities protected by the First Amendment. But doing such discourages political participation. They used facial recognition on social media photos to identify people at the Freddie Gray protests and target them for unnecessary arrests. Digging a little bit deeper into facial recognition, Gebru discusses the usage of facial recognition in big tech corporations such as IBM and Google. She found that there were high error rates for darker-skinned women and light-skinned people. The reason for such was a lack of diversity in data sets that people use. A lot of data comes from exclusively western settings. Similarly, a lot of experiments exclusively use men. For example, in clinical trials, medicine is tested on men only. As a result, women tend to suffer more. The same is true with safety testing using dummies. A lot of the times, testing, especially for vehicle safety, use male dummies. In the real world, women are disproportionately harmed. There is also a lot of harm for transgender individuals, especially in gender recognition. There are issues with misgendering, and facial recognition also assumes that gender is binary. On the bright side, there have been an increasing amount of pushback. Gebru is a part of an organization called Black in AI, which is “a place for sharing ideas, fostering collaboration, and discussing initiatives to increase the presence of Black people in the field of AI”. People are also combatting facial recognition through interesting makeup that fools facial recognition, fashion that people wear to fool facial recognition, and systems of refusal in engaging with this technology.</p>
<p>As used today, computer vision is harmful to underrepresented minorities and women because large corporations and privileged groups are using computer vision to gain power, profits, or control populations.</p>
<p>A question I have for Timnit: In your 2020 lecture you explain that “there are very few people who are black, especially in the Computer Vision community”. There are also very few women. Being a woman of color in the computer vision community, have you felt imposter syndrome? If so, how do you handle such feelings?   Part 2:</p>
<p>We listened to Timnit Gebru’s lecture on “Eugenics and the Promise of Utopia through Artificial General Intelligence”. In her discussion, she starts by explaining how many people are not getting rich from AI. Contrary to popular beliefs, creating well-functioning and modern AI require exploited workers. Their job is to supply data without getting compensation. For instance, Kenyan workers are paid less than $2 per hour to moderate explicit and violent content to help produce work like ChatGPT. So, when wealthy individuals talk about the benefits of AI, they fail to acknowledge the harms to underprivileged people and exploited employees.</p>
<p>Furthermore, Gebru connects AGI to Eugenics. Starting with the discussion of AGI, Gebru explains how the definition of AGI is not well-defined. When people attempt to discuss AGI, they explain AGI as an autonomous system that can outperform and out-think humans. It almost sounds like God. And this way of thinking is rooted in the 20th century Anglo-American thinking, such as Eugenics.</p>
<p>When thinking about Eugenics, many people connect the movement to Nazis and believe that eugenics disappeared at the end of World War II. However, eugenics continue. We can split eugenics into three waves, but Gebru focuses on the first two. In the first wave, the goal of eugenics was to “improve the human stock through negative eugenics”. We can define negative eugenics as the attempt to get rid of undesirable traits because it would help improve the overall human race. Undesirable traits include idiocrasy, specific skin colors, disabilities, etc. This caused discrimination against under-represented groups. And we saw this will the mass genocide of Jews during World War II. After the first wave of eugenics, which died at the end of WWII, we entered the second wave of eugenics. The goal of the second wave was to improve the human stock through positive eugenics. This includes giving people the ability to design their children or encouraging people with desirable traits to reproduce more. But within Eugenics, we see people strive to “transcend humanism”, emerge with technology, and explode with intelligence.</p>
<p>We see this goal arise with AGI as well. The goal of many people is to enhance the human race and grow beyond what humans are capable of. And this leads us to the TESCREAL bundle. AGI can lead to utopia, or it can lead to an apocalypse. Starting with AGI utopia, we saw the idea of utopia emerge during the first and second wave eugenics. But in short, if we produce the necessary technology, we can bloom and thrive. On the other hand, technology can go wrong and lead to an apocalypse. People often oversimplify technology and the future of technology by classifying it as either a utopia or an apocalypse. In reality, AGI has started a race to the bottom. Every company feels like they have to create a certain model that can do everything. And this leads to a lot of centralization of power. This makes it difficult for small organizations to get funding for projects and products. Also, it is often the case that larger companies do subpar work compared to smaller companies. This debunks the idea of AGI Utopia. In terms of AGI Apocalypse, Gebru explains that by talking about at apocalypse, which is much more likely than a utopia, we are detracting accountability from the corporations that are building the machines. Instead, we are placing the blame on the machines itself.</p>
<p>Given this talk, I find that there is accountability that needs to happen, especially within large corporations. The exploitation of workers and the race to the bottom creates dishonesty and a lack of transparency. While there are many points that I agree with, I found Gebru’s talk to be lacking in a lot of ways. The connection between Eugenics and AGI felt like a large leap. There are many goals and ideas that are shared between the communities, but I do not understand the connection between the two. I also found her talk to be lacking in concrete evidence. That also made me skeptical about her lecture. I would also like to discuss her reaction to challenges and disagreements in her argument. The question-and-answer portion of her lecture seemed unprofessional. When presented with a question that opposed her opinions, she immediately shut the audience member down, exclaiming that it was inappropriate to ask such questions. That discredited her even more because having a strong understanding in a topic suggests that you understand both sides of an argument. Having a professional conversation about a controversial topic is much more beneficial and persuasive if the conversation presents facts and is calm. The fact that she refused to hear and answer someone’s question that challenges her beliefs partially suggests that she lacks the understanding of the other side.</p>
<p>I thoroughly enjoyed hearing about her background in our in-class portion. She paved the way for many POC women in computer science. And her experiences are inspiring. However, I was set back by the lecture aspect. I understand that she’s extremely passionate about eugenics and AIG. But after that lecture, I am skeptical about her research.</p>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>