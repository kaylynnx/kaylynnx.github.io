{
 "cells": [
  {
   "cell_type": "raw",
   "id": "5118fbd4-b766-4b0d-a096-a30da6407829",
   "metadata": {},
   "source": [
    "---\n",
    "title: Op Ed Blog\n",
    "author: Kaylynn Xia\n",
    "date: '2023-05-15'\n",
    "image: \"image.jpg\"\n",
    "description: \"OpEd - Bias and Discrimination in AI Hiring and Recruitment\"\n",
    "bibliography: refs.bib\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a8b143-0bbc-46cc-9ff6-a5b316b13f11",
   "metadata": {},
   "source": [
    "In 2020, Covid-19 rampaged throughout the world putting a halt on life. People were suddenly out of work, away from their education, and locked up in their homes. People needed to adapt to the sudden changes and started doing everything remotely including working, learning, shopping, and socializing. Included was the use of Machine Learning and Artificial Intelligence to hire new employees. All of this is new and revolutionary – absolutely brilliant. What could go wrong?\n",
    "\n",
    "Put simply, bias and discrimination emerge from the AI hiring practices. As a quick background, in September 2020, I enrolled in college and immediately knew what I wanted to do with my career. Despite my family’s pressure to go into software development or product management, I wanted to go into finance. At the time, I was set on investment banking at a bulge bracket bank, which includes Goldman Sachs, Morgan Stanley, and Barclays. So, I started recruiting. To my surprise, all recruitment efforts were through a company called Hire Vue. The recruitment meetings were incredibly odd. Not only was I swimming in new waters, learning new finance material on top of all of my classes, but also, I needed to talk to computer that would assess my charisma and intelligence. What shocked me was that I never seemed to master the recruitment meetings. I was always let down despite my hard work. My close friends also seemed to struggle. Not surprisingly, it seemed like women, people of color, people in the LGBTQ community, and people of color struggled disproportionately more than white, cisgendered men. Hire Vue introduced me to the bias and discrimination largely found in finance, a white male dominated career.\n",
    "\n",
    "To understand the biases found in AI hiring and recruitment, let’s take a deeper dive into the use of Machine Learning to recruit employees. First, a company like Hire Vue does a lot more than conduct interviews. They assess one’s resume and look at your personality on your social media. When looking at one’s resume, AI assess it by “searching for keywords and comparing those to the preferred knowledge or experience that the company is looking for” (@Tullier_2021). Afterwards, the AI sorts and selects candidates who would best fit the job description. I think that it’s simple-minded because it seems like you’ll be punished for not using buzz words. Also, the point of a resume is to show your previous skills, the unique skills you bring to the table, and to show your personality. None of that can be observed by cross checking and comparing keywords. AI can also create and assess personality profiles. The AI is trained so that “once the company inputs the candidate’s online information into the system, it will produce an analysis of their personality” (@Tullier_2021), which will understand what the person is like. Again, this is full of bias. This categorizes people they don’t know based off of stereotypes. How do you know my personality off of one image? If I wear glasses, am I smarter? If I am a female Asian, does that make me slower or smarter than a white male counterpart? Finally, AI is able to conduct virtual interviews. Within Hire Vue, for instance, they record the interview and analyze their personality through facial movements, word choice, and speaking voice. Then the “interview is analyzed by AI and then compared to the performances of the company’s top employees” (@Tullier_2021). This is incredibly problematic, especially in fields dominated by white men. First, if the company is dominated by white men, the chances that women or people of color are hired diminish. Second, they look at the interview to understand your personality. Do they give you negative marks if you are disable, a person of color, or a woman? Also, how do they assess personality? Frankly, this is discriminatory. \n",
    "\n",
    "The article, “Does AI Debias Recruitment”, validate the claims that AI hiring, and recruitment are in fact biased. They claim that that the “rapid growth of the field of recruitment AI fails to meaningfully reckon with what race and gender are and how they are embedded in recruitment AI systems, which hold serious implications for the anti-bias claims of these technologies” (@Drage_Mackereth_2022). The authors Drage and Mackereth talk about race and gender, explaining that “AI is an observational apparatus whose production of gendered and racialized bodies always refers to and re-animates a previous source” (@Drage_Mackereth_2022). When hiring individuals, AI cross references previous hiring. In a white male dominated company or industry, women and people of color are disproportionately affected. Drage and Mackereth also explain the harms in claiming debias because “rather than identifying and addressing structural problems, the rhetoric of diversity and unconscious bias and ultimately mask responsibility and circumvent accountability for racist and sexist harms” (@Drage_Mackereth_2022). AI recruitment tools continue to bias they do not hold themselves responsible for their actions. It is further troublesome because AI recruitment tools continue to bias. They “have received relatively little scrutiny in academic literature from the AI ethics community compared to other forms of AI development and deployment” (@Drage_Mackereth_2022). Large corporations and large tech companies are not held responsibility for the inequities and inequalities. \n",
    "\n",
    "The inequalities extend further than women and people of color. People with disabilities are disproportionately harmed compared to abled people. One year ago, the federal government came out and said that “the artificial intelligence technology to screen new job candidates or monitor worker productivity can unfairly discriminated against people with disabilities” (@Press_2022). Often times, AI tools scan and screen people, giving those with speech impediments, arthritis, PTSD, or pregnancy-related disabilities negative marks. While disabled, the disabilities do not hinder productivity. As a result, there has been a greater push to make AI tools more regulated and to foster positive advancements in AI technology. For instance, President Joe Biden, who has a speech impediment, has been pushing for greater regulation(@Press_2022). The EEOC, which is responsible for enforcing laws against workplace discrimination, has been pushing for greater transparency and equality (@Press_2022). \n",
    "\n",
    "It is visible that there is a lot more work to do to mitigate the harms of AI hiring and recruitment. There have been many people who have been discriminated against, especially at the height of the Covid-19 pandemic. Nothing will fix the discrimination my friends and I faced, though we can work together to improve. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
